{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch_geometric as tg\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pathlib import PurePath\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "\n",
    "from xml.dom import minidom\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method to create one hot encoders\n",
    "\n",
    "Input: Array with string\n",
    "'''\n",
    "def one_hot_string(map):\n",
    "    values = np.array(map)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    \n",
    "    return onehot_encoded\n",
    "\n",
    "'''\n",
    "    Get action name from one-hot-encoding\n",
    "'''\n",
    "def get_action_from_encoding(enc):\n",
    "    idx = _actions.index(enc)\n",
    "    return action_map[idx], idx\n",
    "\n",
    "'''\n",
    "    Create a dict with temporal information\n",
    "'''\n",
    "def createTemporalDict(in_dict):\n",
    "    temporal_concat = {}\n",
    "    \n",
    "    for key in in_dict:\n",
    "        temporal_concat[key] = {}\n",
    "        for seq in in_dict[key]:\n",
    "                    temporal_concat[key][seq] = [concatenateTemporal(in_dict[key][seq])]\n",
    "    return temporal_concat\n",
    "\n",
    "'''\n",
    "    See if two nodes match\n",
    "'''\n",
    "def nodesMatch(n1, n_list):\n",
    "    for i, node in enumerate(n_list, start=0):\n",
    "        if node[1] == n1:\n",
    "            return True, i\n",
    "\n",
    "    return False, 0\n",
    "\n",
    "'''\n",
    "    Calculate the temporal edges\n",
    "    # nodes will start at node_index_list.last + 1\n",
    "'''\n",
    "def calculateTemporalEdges(full_gr, nodes, index_list):\n",
    "    temporal_rel = _relations[spatial_map.index(\"temporal\")]\n",
    "    old_nodes = []\n",
    "    node_cnt = index_list[-1]\n",
    "\n",
    "\n",
    "    for index in index_list:\n",
    "        old_nodes.append(full_gr.nodes[index])\n",
    "\n",
    "    for index in index_list:\n",
    "        match, ind = nodesMatch(full_gr.nodes[index], nodes)\n",
    "        if match:\n",
    "            full_gr.add_edge(index, node_cnt, edge_attr=temporal_rel)\n",
    "            node_cnt += 1\n",
    "\n",
    "'''\n",
    "    Function to create the temporal information between graphs.\n",
    "    Input: list of graphs\n",
    "'''\n",
    "def concatenateTemporal(graphs):\n",
    "    graph_nx = nx.DiGraph()\n",
    "    graph_nx.graph[\"features\"] = graphs[0].graph['features']\n",
    "    node_cnt = 0\n",
    "    node_index_list = []\n",
    "\n",
    "    for i, graph in enumerate(graphs, start=0):\n",
    "\n",
    "        if len(node_index_list) > 0:\n",
    "            calculateTemporalEdges(graph_nx, graph.nodes(data=True), node_index_list)\n",
    "\n",
    "        node_index_list = []\n",
    "\n",
    "        for node in graph.nodes(data=True):\n",
    "            graph_nx.add_node(node_cnt, x=node[1]['x'])\n",
    "            node_index_list.append(node_cnt)\n",
    "            node_cnt += 1\n",
    "            \n",
    "        for edge in graph.edges():\n",
    "            graph_nx.add_edge(node_index_list[edge[0]], node_index_list[edge[1]], edge_attr=graph.get_edge_data(edge[0], edge[1])['edge_attr'])\n",
    "\n",
    "    empty_list = []\n",
    "    for node in graph_nx.nodes(data=True):\n",
    "        if node[1] == {}:\n",
    "            empty_list.append(node[0])\n",
    "\n",
    "    for node in empty_list:\n",
    "        graph_nx.remove_node(node)\n",
    "\n",
    "\n",
    "    return graph_nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    WARNING WARNING WARNING \n",
    "    DO NOT CHANGE ORDER OF THESE ITEMS\n",
    "'''\n",
    "objects = ['LeftHand', 'RightHand', 'banana', 'bottle', 'bowl', 'cereals', 'cup', 'cuttingboard', \n",
    "          'hammer', 'harddrive', 'knife', 'saw', 'screwdriver', 'sponge', 'whisk', 'woodenwedge']\n",
    "\n",
    "spatial_map = ['above', 'behind of', 'below', 'contact', 'fixed moving together', 'getting close',\n",
    "              'halting together', 'in front of', 'inside', 'left of', 'moving apart', 'moving together', \n",
    "                'right of', 'stable', 'surround', 'temporal']\n",
    "\n",
    "\n",
    "action_map = ['approach', 'cut', 'drink', 'hammer', 'hold', 'idle', 'lift', 'place', 'pour', 'retreat', \n",
    "              'saw', 'screw', 'stir', 'wipe']\n",
    "\n",
    "original_index = ['idle', 'approach', 'retreat', 'lift', 'place', 'hold', 'pour', 'cut',\n",
    "                 'hammer', 'saw', 'stir', 'screw', 'drink', 'wipe']\n",
    "\n",
    "_relations = one_hot_string(spatial_map).tolist()\n",
    "_actions = one_hot_string(action_map).tolist()\n",
    "_objects = one_hot_string(objects).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_list(path):\n",
    "    # ['DREHER', 'bimacs_derived_data', 'subject_1', 'task_5_k_cereals', 'take_3', 'spatial_relations', 'frame_0.json']\n",
    "    final_path = './' + path[0] + '/bimacs_derived_data_3D/' + path[2] + '/' + path[3] + '/' + path[4] + '/3d_objects/' + path[6]\n",
    "    with open(final_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    temp_dict = {}\n",
    "    cnt = 0\n",
    "\n",
    "    for obj in data:\n",
    "        temp_dict[cnt] = obj['class_name']\n",
    "        cnt += 1\n",
    "    \n",
    "    return temp_dict\n",
    "\n",
    "\n",
    "# Takes a single JSON file and outputs a graph\n",
    "def json_to_graph(input_path, target):\n",
    "    graph = nx.DiGraph()\n",
    "    \n",
    "    node_list_path = os.path.normpath(input_path).split(os.sep)\n",
    "    node_list = get_object_list(node_list_path)\n",
    "    \n",
    "    # Load JSON Object to list\n",
    "    with open(input_path) as f:\n",
    "          data = json.load(f)\n",
    "    \n",
    "    for index, name in node_list.items():\n",
    "        graph.add_node(index, x=_objects[objects.index(name)])\n",
    "    \n",
    "    # Populate the graph with nodes and edges\n",
    "    for obj in data:  \n",
    "        relation_name = obj['relation_name']\n",
    "        graph.add_edge(obj['object_index'], obj['subject_index'], edge_attr=_relations[spatial_map.index(relation_name)])\n",
    "    \n",
    "    # If the ground truth contain null value set the action to undefined\n",
    "    if(target is None):\n",
    "        return -1\n",
    "        #graph.graph['features'] = _actions[action_map.index('undefined')]\n",
    "    else:\n",
    "        #action_map.index(original_index[target])\n",
    "        graph.graph[\"features\"] = _actions[action_map.index(original_index[target])]\n",
    "    \n",
    "    if len(graph.nodes()) == 0:\n",
    "        print(\"------- NO NODES\")\n",
    "        return -1\n",
    "    \n",
    "    if len(graph.edges()) == 0:\n",
    "        print(\"------- NO EDGES\")\n",
    "        return -1\n",
    "    \n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "def get_target_action(cnt, ground_truth):\n",
    "    # Find target by comparing the frame count with ground truth\n",
    "    for index, item in enumerate(ground_truth['right_hand']):\n",
    "        if(index % 2 == 0 and index != 0):\n",
    "            if(cnt <= item):\n",
    "                return ground_truth['right_hand'][index-1]  \n",
    "    return 'Not found'\n",
    "\n",
    "def take_to_graph_list(path):\n",
    "    graph_list = []\n",
    "    # Get ground truth path\n",
    "    gt_name = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')][0]\n",
    "    gt_path = path + gt_name\n",
    "    \n",
    "    # Extract all json files in spatial_relations and sort them\n",
    "    json_files = [pos_json for pos_json in os.listdir(path + 'spatial_relations') if pos_json.endswith('.json')]\n",
    "    json_files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    \n",
    "    # Load ground truth\n",
    "    with open(gt_path) as f:\n",
    "          ground_truth = json.load(f)\n",
    "    \n",
    "    for file in json_files:\n",
    "        frame_cnt = int(re.search(r'\\d+', file).group())\n",
    "        graphs = json_to_graph(path + 'spatial_relations/' + file, get_target_action(frame_cnt, ground_truth))\n",
    "        \n",
    "        if graphs != -1:\n",
    "            graph_list.append(graphs)\n",
    "        else:\n",
    "            print(\"file:\", file, \"frame_cnt:\", frame_cnt, \"gt:\", ground_truth)\n",
    "    \n",
    "    return graph_list\n",
    "\n",
    "\n",
    "def generate_graphs(_seperate=True):\n",
    "    \n",
    "    if _seperate:\n",
    "        print(\"Creating graphs to dict.\")\n",
    "        all_data = {}\n",
    "    else:\n",
    "        print(\"Appending graphs to array.\")\n",
    "        all_data = []\n",
    "    \n",
    "    # Iterate subjects\n",
    "    for dic in list(glob.glob(MAIN_PATH+'/*/')):\n",
    "        # Iterate tasks\n",
    "        for sub_dic in list(glob.glob(dic+'/*/')):\n",
    "            # Iterate takes\n",
    "            for sub_sub_dic in list(glob.glob(sub_dic+'/*/')):\n",
    "                # Get subject number\n",
    "                sub = int(re.search(r'\\d+', dic).group())\n",
    "                # Get task number\n",
    "                task = int(re.search(r'\\d+', sub_dic[len(dic):]).group())\n",
    "                # Get take number\n",
    "                take = int(re.search(r'\\d+', sub_sub_dic[len(sub_dic):]).group())\n",
    "                name = \"take_\" + str(sub) + \"_\" + str(task) + \"_\" + str(take)\n",
    "                \n",
    "                if _seperate:\n",
    "                    all_data[name] = take_to_graph_list(sub_sub_dic)\n",
    "                else:\n",
    "                    all_data += take_to_graph_list(sub_sub_dic)\n",
    "             \n",
    "    return all_data\n",
    "\n",
    "MAIN_PATH = \"./DREHER/bimacs_derived_data\"\n",
    "SECOND_PATH = \"./DREHER/bimacs_derived_data_3D\"\n",
    "\n",
    "#test = generate_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "class DreherDataset(Dataset):\n",
    "    \"\"\"Dreher Dataset dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, window=0, root_dir=None, transform=None):\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.root_dir = root_dir\n",
    "        self.samples = generate_graphs(_seperate=False)\n",
    "        self.transform = transform\n",
    "        self.window = window\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if self.window > 1:\n",
    "            current_action = self.samples[idx].graph['features']\n",
    "            step_back = 0\n",
    "\n",
    "            for i in range(self.window):\n",
    "                if self.samples[idx+i].graph['features'] != current_action:\n",
    "                    step_back += 1\n",
    "\n",
    "            if step_back > 0:\n",
    "                x = self.samples[idx-step_back:idx+self.window-step_back]\n",
    "            else:\n",
    "                x = self.samples[idx:idx+self.window]\n",
    "        else:\n",
    "            x = self.samples[idx]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    This is used to create new datasets.\n",
    "    \n",
    "    Example:\n",
    "    train_set = DreherDataset( window=n )\n",
    "    \n",
    "    if window = 0, 1 graph will be made.\n",
    "    if window > 0, x number of graphs will be created together\n",
    "    \n",
    "    temporal = False, will not add temporal information between nodes\n",
    "    if tempral = True, will add temporal information between nodes\n",
    "\n",
    "'''\n",
    "_SAVE_RAW_DATA = False\n",
    "_CREATE_DATASET = False\n",
    "\n",
    "_TIME_WINDOW = 8\n",
    "\n",
    "if _CREATE_DATASET:\n",
    "    train_set = DreherDataset(window=_TIME_WINDOW)\n",
    "\n",
    "\n",
    "# USED TO SAVE RAW TRAINING DATA\n",
    "if _SAVE_RAW_DATA:\n",
    "    with open(os.path.join(_FOLDER + \"raw/training_\" + str(_TIME_WINDOW) + \"w.pt\"), 'wb') as f:\n",
    "                torch.save(train_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_tar)\n",
    "\n",
    "class DreherDS(InMemoryDataset):\n",
    "    def __init__(self,\n",
    "                root,\n",
    "                dset=\"train\",\n",
    "                transform=None):\n",
    "        super(DreherDS, self).__init__(root, transform)\n",
    "\n",
    "        if dset == \"train\":\n",
    "            path = self.processed_paths[0]\n",
    "        elif dset == \"valid\":\n",
    "            path = self.processed_paths[1]\n",
    "        else:\n",
    "            path = self.processed_paths[2]\n",
    "\n",
    "        self.data, self.slices = torch.load(path)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['dreher_train_disc_4w.pt', \n",
    "                'dreher_val_disc_4w.pt',\n",
    "                'dreher_test_disc_4w.pt']\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['dreher_train_disc_10w.pt', \n",
    "                'dreher_test_disc_10w.pt',\n",
    "                'dreher_test_disc_4w.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        return\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)\n",
    "    \n",
    "    def process(self):\n",
    "        big_slices = []\n",
    "        for raw_path, path in zip(self.raw_paths, self.processed_paths):\n",
    "            big_data = []\n",
    "            graphs = torch.load(raw_path)\n",
    "            j = 0\n",
    "            for graph in graphs:\n",
    "                G = nx.convert_node_labels_to_integers(graph)\n",
    "                G = G.to_directed() if not nx.is_directed(G) else G\n",
    "                edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "\n",
    "                data = {}\n",
    "\n",
    "                for i, (_, feat_dict) in enumerate(G.nodes(data=True)):\n",
    "                    for key, value in feat_dict.items():\n",
    "                        data[key] = [value] if i == 0 else data[key] + [value]\n",
    "\n",
    "                for i, (_, _, feat_dict) in enumerate(G.edges(data=True)):\n",
    "                    for key, value in feat_dict.items():\n",
    "                        data[key] = [value] if i == 0 else data[key] + [value]\n",
    "\n",
    "                for key, item in data.items():\n",
    "                    try:\n",
    "                        data[key] = torch.tensor(item)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "                data['edge_index'] = edge_index.view(2, -1)\n",
    "                data = tg.data.Data.from_dict(data)\n",
    "                data.num_nodes = len(graph)\n",
    "                data.y = torch.tensor(graph.graph['features'])\n",
    "                \n",
    "                big_data.append(data)\n",
    "\n",
    "            torch.save(self.collate(big_data), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DreherDS('/data/tmp/dj_data/', \"train\")\n",
    "val_dataset = DreherDS('/data/tmp/dj_data/', \"valid\")\n",
    "test_dataset = DreherDS('/data/tmp/dj_data/', \"test\")\n",
    "\n",
    "print(\"TRAIN DATASET:\", len(train_dataset))\n",
    "print(\"VALID DATASET:\", len(val_dataset))\n",
    "print(\"TEST DATASET:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "max_count = 1\n",
    "_bs = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=_bs, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=_bs, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=_bs, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_batch, to_dense_adj, to_scipy_sparse_matrix\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "'''\n",
    "    Creates a dense adjacency matrix from pg data.\n",
    "    With normalization\n",
    "'''\n",
    "def to_dense_adj_max_node(edge_index, x, edge_attr, batch=None, max_node=None):\n",
    "    if batch is None:\n",
    "        batch = edge_index.new_zeros(edge_index.max().item() + 1)\n",
    "    \n",
    "    batch_size = batch[-1].item() + 1\n",
    "    \n",
    "    if max_node is None:\n",
    "        max_num_nodes = num_nodes.max().item()\n",
    "    else:\n",
    "        max_num_nodes = max_node\n",
    "    \n",
    "    one = batch.new_ones(batch.size(0))\n",
    "    num_nodes = scatter_add(one, batch, dim=0, dim_size=batch_size)\n",
    "    cum_nodes = torch.cat([batch.new_zeros(1), num_nodes.cumsum(dim=0)])\n",
    "    \n",
    "    size = [batch_size, max_num_nodes, max_num_nodes]\n",
    "    \n",
    "    size = size\n",
    "    dtype = torch.float\n",
    "    \n",
    "    adj = torch.zeros(size, dtype=dtype, device=edge_index.device)\n",
    "\n",
    "    edge_index_0 = batch[edge_index[0]].view(1, -1)\n",
    "    edge_index_1 = edge_index[0] - cum_nodes[batch][edge_index[0]]\n",
    "    edge_index_2 = edge_index[1] - cum_nodes[batch][edge_index[1]]\n",
    "    \n",
    "    # Normalize the edges on the length of pre-defined spatial objects.\n",
    "    _ea = []\n",
    "    for ea in edge_attr:\n",
    "        _ea.append((ea[0].item()+1)/len(spatial_map))\n",
    "\n",
    "    adj[edge_index_0, edge_index_1, edge_index_2] = torch.FloatTensor(_ea).cuda()\n",
    "\n",
    "    # Normalize objects in the diagonal\n",
    "    objects_sum = x.argmax(dim=1).type(dtype)\n",
    "    objects_sum = objects_sum/len(_objects)\n",
    "\n",
    "    object_size = [batch_size, num_nodes.max().item()]\n",
    "    object_mat = torch.zeros(object_size, dtype=dtype, device=edge_index.device)\n",
    "    \n",
    "    obj_offset = 0\n",
    "    \n",
    "    # Creates the adjacency matrix of size [max_node*max_node].\n",
    "    for b in range(batch_size):\n",
    "        temp = torch.zeros(num_nodes.max().item(), dtype=dtype, device=edge_index.device)\n",
    "        _obj = objects_sum[obj_offset:(obj_offset+num_nodes[b])].type(dtype)\n",
    "        obj_offset += num_nodes[b]\n",
    "        dd = torch.cat((_obj, temp), dim=0)\n",
    "        dd = dd[:num_nodes.max().item()]\n",
    "        object_mat[b] = dd\n",
    "            \n",
    "    adj.as_strided(object_mat.size(), [adj.stride(0), adj.size(2) + 1]).copy_(object_mat)\n",
    "    \n",
    "    # Error check to see that the diagonal is not zero.\n",
    "    for i in range(len(adj)):\n",
    "        if torch.diag(adj[i]).sum().item() == 0:\n",
    "            print(\"ERROR! ZERO DIAGONAL!\", i)\n",
    "\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_batch, to_dense_adj, to_scipy_sparse_matrix\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "'''\n",
    "    Creates a dense adjacency matrix from pg data.\n",
    "    Without normalization\n",
    "'''\n",
    "def to_dense_adj_max_node(edge_index, x, edge_attr, batch=None, max_node=None):\n",
    "    if batch is None:\n",
    "        batch = edge_index.new_zeros(edge_index.max().item() + 1)\n",
    "    \n",
    "    batch_size = batch[-1].item() + 1\n",
    "    \n",
    "    if max_node is None:\n",
    "        max_num_nodes = num_nodes.max().item()\n",
    "    else:\n",
    "        max_num_nodes = max_node\n",
    "    \n",
    "    one = batch.new_ones(batch.size(0))\n",
    "    num_nodes = scatter_add(one, batch, dim=0, dim_size=batch_size)\n",
    "    cum_nodes = torch.cat([batch.new_zeros(1), num_nodes.cumsum(dim=0)])\n",
    "    \n",
    "    size = [batch_size, max_num_nodes, max_num_nodes]\n",
    "    \n",
    "    size = size\n",
    "    dtype = torch.float\n",
    "    \n",
    "    adj = torch.zeros(size, dtype=dtype, device=edge_index.device)\n",
    "\n",
    "    edge_index_0 = batch[edge_index[0]].view(1, -1)\n",
    "    edge_index_1 = edge_index[0] - cum_nodes[batch][edge_index[0]]\n",
    "    edge_index_2 = edge_index[1] - cum_nodes[batch][edge_index[1]]\n",
    "    \n",
    "    # Normalize the edges on the length of pre-defined spatial objects.\n",
    "    _ea = []\n",
    "    for ea in edge_attr:\n",
    "        _ea.append(1)\n",
    "\n",
    "    adj[edge_index_0, edge_index_1, edge_index_2] = torch.FloatTensor(_ea).cuda(device)\n",
    "\n",
    "    # Normalize objects in the diagonal\n",
    "    objects_sum = x.argmax(dim=1).type(dtype)\n",
    "    objects_sum[objects_sum > 0] = 1\n",
    "\n",
    "    object_size = [batch_size, num_nodes.max().item()]\n",
    "    object_mat = torch.zeros(object_size, dtype=dtype, device=edge_index.device)\n",
    "    \n",
    "    obj_offset = 0\n",
    "    \n",
    "    # Creates the adjacency matrix of size [max_node*max_node].\n",
    "    for b in range(batch_size):\n",
    "        temp = torch.zeros(num_nodes.max().item(), dtype=dtype, device=edge_index.device)\n",
    "        _obj = objects_sum[obj_offset:(obj_offset+num_nodes[b])].type(dtype)\n",
    "        obj_offset += num_nodes[b]\n",
    "        dd = torch.cat((_obj, temp), dim=0)\n",
    "        dd = dd[:num_nodes.max().item()]\n",
    "        object_mat[b] = dd\n",
    "            \n",
    "    adj.as_strided(object_mat.size(), [adj.stride(0), adj.size(2) + 1]).copy_(object_mat)\n",
    "    \n",
    "    # Error check to see that the diagonal is not zero.\n",
    "    for i in range(len(adj)):\n",
    "        if torch.diag(adj[i]).sum().item() == 0:\n",
    "            print(\"ERROR! ZERO DIAGONAL!\", i)\n",
    "\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_nodes_train = max([len(i.x) for i in train_dataset])\n",
    "print(\"max in train:\", max_num_nodes_train)\n",
    "\n",
    "max_num_nodes_valid = max([len(i.x) for i in val_dataset])\n",
    "print(\"max in train:\", max_num_nodes_valid)\n",
    "\n",
    "max_num_nodes_test = max([len(i.x) for i in test_dataset])\n",
    "print(\"max in train:\", max_num_nodes_test)\n",
    "\n",
    "max_num_nodes = max(max_num_nodes_train, max_num_nodes_valid)\n",
    "print(\"MAX:\", max_num_nodes)\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, ReLU, ELU\n",
    "from torch_geometric.nn import NNConv, radius_graph, fps, global_mean_pool\n",
    "from torch_scatter import scatter_mean\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "input_size=len(action_map) # static value\n",
    "output_size=len(action_map) # static value\n",
    "channels = 64\n",
    "\n",
    "_PRINT = False # Used for debugging\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lin = torch.nn.Linear(len(objects), channels)\n",
    "\n",
    "        nn = Sequential(Linear(len(spatial_map), 512), ReLU(), Linear(512, channels * channels *2))\n",
    "\n",
    "        self.conv1 = NNConv(channels, channels*2, nn, aggr='mean') \n",
    "        self.bn1 = BatchNorm(channels*2)\n",
    "        self.conv2 = NNConv(channels*2, channels, nn, aggr='mean')\n",
    "        \n",
    "        nn2 = Sequential(Linear(len(spatial_map), 512), ReLU(), Linear(512, 2 * channels * 64  ))\n",
    "        self.mu = NNConv(channels*2, 64, nn2, aggr='mean')\n",
    "        self.logvar = NNConv(channels*2, 64, nn2, aggr='mean')\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        out = F.relu(self.lin(data.x)) # Fully connected\n",
    "        \n",
    "        # Action prediction\n",
    "        hidden = F.relu(self.conv1(out, data.edge_index, data.edge_attr)) # conv1\n",
    "        hidden = self.bn1(hidden)\n",
    "        conv2_out = F.relu(self.conv2(hidden, data.edge_index, data.edge_attr)) # conv2\n",
    "        \n",
    "        # Reconstruction\n",
    "        mu = self.mu(hidden, data.edge_index, data.edge_attr)\n",
    "        logvar = self.logvar(hidden, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        mu = scatter_mean(mu, batch, dim=0)\n",
    "        logvar = scatter_mean(logvar, batch, dim=0)\n",
    "        \n",
    "        p_x = scatter_mean(conv2_out, batch, dim=0)\n",
    "        \n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        if self.training:\n",
    "            return std * eps + mu, logvar, mu, p_x\n",
    "        else:\n",
    "            return mu, logvar, mu, p_x\n",
    "\n",
    "class Predictor(torch.nn.Module):\n",
    "    def __init__(self, input_size, seq_len, hidden_size, n_layers):\n",
    "        super(Predictor, self).__init__()\n",
    "        \n",
    "        self.prev_hidden = None\n",
    "        self.bs = _bs\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(self.input_size, self.hidden_size, self.n_layers, dropout=0.1, batch_first=True)\n",
    "        self.lin1 = torch.nn.Linear(self.hidden_size, len(action_map))\n",
    "    \n",
    "    def forward(self, p_x):\n",
    "        \n",
    "        if self.prev_hidden is None:\n",
    "            self.prev_hidden = (torch.zeros(self.n_layers, self.bs, self.hidden_size).cuda(device),\n",
    "                                torch.zeros(self.n_layers, self.bs, self.hidden_size).cuda(device))\n",
    "\n",
    "\n",
    "        input_reshape = p_x.reshape( self.bs, self.seq_len, -1 ).to(device)\n",
    "\n",
    "        q, h = self.lstm( input_reshape , self.prev_hidden )\n",
    "        \n",
    "        self.prev_hidden = repackage_hidden(h)\n",
    "        \n",
    "        out = self.lin1(q[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 256)\n",
    "        self.fc2 = nn.Linear(256, max_num_nodes*max_num_nodes)\n",
    "    \n",
    "    def forward(self, z_x):\n",
    "\n",
    "        out = F.relu(self.fc1(z_x))\n",
    "        out = self.fc2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class djNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(djNet, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        self.predictor = Predictor(8, 8, 8, 2)\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z, logvar, mu, p_x = self.encoder(x)\n",
    "        q_z = self.decoder(z)\n",
    "        p_z = self.predictor(p_x)\n",
    "        \n",
    "        return q_z, logvar, mu, z, p_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = djNet()\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_criterion(inputs, targets, logvar, mu, ap_inputs, ap_targets):\n",
    "    # Reconstruction loss\n",
    "    bce_loss = F.binary_cross_entropy(inputs, targets, reduction=\"sum\")\n",
    "    \n",
    "    # Action prediction loss\n",
    "    ap_loss = ap_criterion(ap_inputs, ap_targets)\n",
    "\n",
    "    # Regularization term\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())    \n",
    "\n",
    "    return bce_loss + kl_loss, ap_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#writer = SummaryWriter(comment=\"MANIAC_4w_dropout02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(loader, model):\n",
    "    model.train()\n",
    "    \n",
    "    recon_loss_all = 0\n",
    "    ap_loss_all = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "\n",
    "        y_hat, logvar, mu, _, y_ap = model(data)\n",
    "        prediction = y_hat.view(_bs, -1, max_num_nodes)\n",
    "\n",
    "        # Creating targets\n",
    "        target_adj = to_dense_adj_max_node(data.edge_index, data.x, data.edge_attr, data.batch, max_num_nodes)\n",
    "        target = data.y.view(_bs, -1)\n",
    "        y_ap_true = target.argmax(axis=1)\n",
    "\n",
    "        # Compute loss\n",
    "        recon_loss, ap_loss = loss_criterion(prediction, target_adj, logvar, mu, y_ap, y_ap_true)\n",
    "        net_loss = recon_loss * 0.6 + ap_loss\n",
    "\n",
    "        # Compute gradients and updates weights.\n",
    "        net_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        recon_loss_all += recon_loss.item()\n",
    "        ap_loss_all += ap_loss.item()\n",
    "    \n",
    "    return recon_loss_all/(len(loader)*_bs), ap_loss_all/(len(loader)*_bs)\n",
    "\n",
    "def test(loader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    recon_loss_all = 0\n",
    "    ap_loss_all = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "\n",
    "        y_hat, logvar, mu, _, y_ap = model(data)\n",
    "        prediction = y_hat.view(_bs, -1, max_num_nodes)\n",
    "\n",
    "        # Creating targets\n",
    "        target_adj = to_dense_adj_max_node(data.edge_index, data.x, data.edge_attr, data.batch, max_num_nodes)\n",
    "        target = data.y.view(_bs, -1)\n",
    "        y_ap_true = target.argmax(axis=1)\n",
    "        \n",
    "        pred = y_ap.max(1)[1]\n",
    "\n",
    "        # Compute loss\n",
    "        recon_loss, ap_loss = loss_criterion(prediction, target_adj, logvar, mu, y_ap, y_ap_true)\n",
    "\n",
    "        recon_loss_all += recon_loss.item()\n",
    "        ap_loss_all += ap_loss.item()\n",
    "        correct += pred.eq(y_ap_true).sum().item()\n",
    "    \n",
    "    return recon_loss_all/(len(loader)*_bs), ap_loss_all/(len(loader)*_bs), correct/(len(loader)*_bs)\n",
    "\n",
    "        \n",
    "def super_test(loader, model):\n",
    "    model.eval()\n",
    "    ap_predict_list = np.array([])\n",
    "    ap_gt_list = np.array([])\n",
    "    \n",
    "    reconstruct_predict_list = []\n",
    "    reconstruct_gt_list = []\n",
    "    top3_list = []\n",
    "    num_nodes_list = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        batch_size = data.batch[-1].item() + 1\n",
    "\n",
    "        y_hat, logvar, mu, _, y_ap = model(data)\n",
    "        pred = y_ap.max(1)[1]\n",
    "        \n",
    "        # Creating targets\n",
    "        target_adj = to_dense_adj_max_node(data.edge_index, data.x, data.edge_attr, data.batch, max_num_nodes).cuda()\n",
    "        target = data.y.view(_bs, -1)\n",
    "        y_ap_true = target.argmax(axis=1)\n",
    "        \n",
    "        prediction = y_hat.view(_bs, -1, max_num_nodes)\n",
    "        ap_predict_list = np.append(ap_predict_list, pred.cpu().detach().numpy())\n",
    "        ap_gt_list = np.append(ap_gt_list, y_ap_true.cpu().detach().numpy())\n",
    "        \n",
    "        batch_size = data.batch[-1].item() + 1\n",
    "\n",
    "        one = data.batch.new_ones(data.batch.size(0))\n",
    "        num_nodes = scatter_add(one, data.batch, dim=0, dim_size=batch_size)\n",
    "        num_nodes_list.append(num_nodes.cpu().detach().numpy())\n",
    "        \n",
    "        \n",
    "        # Get top 3 predictions\n",
    "        indices = torch.topk(y_ap, 3)\n",
    "        for i in range(len(indices[0])):\n",
    "            batch_top_list = []\n",
    "            for top in indices[0][i].tolist():\n",
    "                batch_top_list.append(action_map[y_ap[i].tolist().index(top)])\n",
    "            \n",
    "            top3_list.append(batch_top_list)\n",
    "\n",
    "        gr_pred = prediction.cpu().detach().numpy()\n",
    "        gr_gt = target_adj.cpu().detach().numpy()\n",
    "\n",
    "        reconstruct_predict_list.append(gr_pred)\n",
    "        reconstruct_gt_list.append(gr_gt)                \n",
    "        \n",
    "    return reconstruct_predict_list, reconstruct_gt_list, ap_predict_list, ap_gt_list, top3_list, num_nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_counter = 0\n",
    "test_ap_acc = 1\n",
    "\n",
    "for epoch in range(1, 501):\n",
    "    \n",
    "    train_recon_loss, train_ap_loss = train(train_loader, model)\n",
    "    _, _, train_ap_acc = test(train_loader, model)\n",
    "    validation_recon_loss, validation_ap_loss, validation_ap_acc = test(valid_loader, model)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': train_ap_loss,\n",
    "        }, \"/data/tmp/dj_data/runs/dreher_\" + str(epoch) + \".pt\")\n",
    "    \n",
    "    if False:\n",
    "        writer.add_scalar('AP_Acc/train', train_ap_acc, epoch)\n",
    "        writer.add_scalar('AP_Acc/validation', validation_ap_acc, epoch)\n",
    "\n",
    "        writer.add_scalar('Recon_Loss/train', train_recon_loss, epoch)\n",
    "        writer.add_scalar('Recon_Loss/validation', validation_recon_loss, epoch)\n",
    "\n",
    "        writer.add_scalar('AP_Loss/train', train_ap_loss, epoch)\n",
    "        writer.add_scalar('AP_Loss/validation', validation_ap_loss, epoch)\n",
    "\n",
    "    \n",
    "    print(\"Epoch {:02d}, [T] RLoss: {:.2f}, APLoss: {:.4f}, Acc: {:.2f}% [V] RLoss: {:.2f}, APLoss: {:.4f}, Acc: {:.2f}%, TAcc: {:.2f}\".format( epoch, \n",
    "                                                                           train_recon_loss,\n",
    "                                                                           train_ap_loss,\n",
    "                                                                           train_ap_acc*100,\n",
    "                                                                           validation_recon_loss,\n",
    "                                                                           validation_ap_loss,\n",
    "                                                                           validation_ap_acc*100,\n",
    "                                                                           test_ap_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAVE = False\n",
    "if _SAVE:\n",
    "    torch.save({\n",
    "                'epoch': 99,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': 4.110431,\n",
    "                }, \"./MANIAC_final_models/MANIAC_final_4w_dim_64_increase_mu_64.pt\")\n",
    "    print(\"SAVED!\")\n",
    "else:\n",
    "    checkpoint = torch.load(\"/data/tmp/dj_data/runs/dreher_10.pt\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(\"LOADED MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_pred, cr_gt, ap_pred, ap_target, top3, node_list = super_test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cm = confusion_matrix(ap_target, ap_pred)\n",
    "\n",
    "print(classification_report(ap_target.astype(int), ap_pred.astype(int), target_names=action_map, labels=[0,1,2,3,4,5,6,7, 8, 9, 10, 11, 12,13,14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = []\n",
    "for i in range(len(top3)):\n",
    "    if action_map[ap_target[i].astype(int)] in top3[i]:\n",
    "        new_pred.append(ap_target[i])\n",
    "    else:\n",
    "        new_pred.append(action_map.index(top3[i][0]))\n",
    "\n",
    "print(\"top 3\")\n",
    "\n",
    "print(classification_report(ap_target.astype(int), new_pred, target_names=action_map, labels=[0,1,2,3,4,5,6,7, 8, 9, 10, 11, 12,13,14]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "_PRED_TRESHOLD = 0.3\n",
    "\n",
    "def calc_auc_roc(gt, pred, node_list):\n",
    "\n",
    "    if len(gt) != len(pred):\n",
    "        raise Exception(\"Invalid length of ground truth and prediction! GT {:d} and pred {:d}\".format(len(gt), len(pred))) \n",
    "    \n",
    "    num_matrix = len(gt)\n",
    "    \n",
    "    _correct_node_length = 0\n",
    "    _correct_objects_length = 0\n",
    "    _correct_objects = 0\n",
    "    _total_objects = 0\n",
    "    _roc_auc_score = 0\n",
    "    _max_nodes_in_graph = 0\n",
    "    _average_precision_score = 0\n",
    "    graph_count = 0\n",
    "    \n",
    "    _node_diff_dict = {0: 0}\n",
    "    \n",
    "    for idx in range(num_matrix):\n",
    "        for i in range(len(gt[idx])):\n",
    "            gt_diag = np.round(np.diag(gt[idx][i]))\n",
    "            cr_diag = np.round(np.diag(pred[idx][i]))\n",
    "            cr_nodes = np.count_nonzero(cr_diag)\n",
    "            graph_count += 1\n",
    "        \n",
    "            if node_list[idx][i] == cr_nodes:\n",
    "                _max_nodes_in_graph = node_list[idx][i]\n",
    "                _correct_objects_length += 1\n",
    "                _node_diff_dict[0] += 1\n",
    "            else:\n",
    "                diff = cr_nodes - node_list[idx][i]\n",
    "                if _node_diff_dict.get(diff) is None:\n",
    "                    _node_diff_dict[diff] = 1\n",
    "                else:\n",
    "                    _node_diff_dict[diff] += 1\n",
    "       \n",
    "            gt_flatten = np.ceil(gt[idx][i].flatten())\n",
    "\n",
    "            pred[idx][pred[idx] <= _PRED_TRESHOLD] = 0\n",
    "            pred[idx][pred[idx] > _PRED_TRESHOLD] = 1\n",
    "\n",
    "            cr_flatten = np.ceil(pred[idx][i].flatten())\n",
    "            _roc_auc_score += roc_auc_score(gt_flatten, cr_flatten)\n",
    "            _average_precision_score += average_precision_score(gt_flatten, cr_flatten)\n",
    "    \n",
    "    print(_node_diff_dict)\n",
    "    print(\"Correct node length:\", _correct_objects_length, \"out of\", graph_count, \"graphs.\", _correct_objects_length/num_matrix)\n",
    "    print(\"Correct objects in place:\", _correct_objects, \"out of\", _total_objects, \"objects\")\n",
    "    print(\"Average ROC AUC SCORE:\", _roc_auc_score/graph_count)\n",
    "    print(\"Average precision score:\", _average_precision_score/graph_count)\n",
    "\n",
    "calc_auc_roc(cr_gt, cr_pred, node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=action_map, yticklabels=action_map, cmap=\"YlGnBu\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Normalized')\n",
    "plt.show(block=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=action_map, yticklabels=action_map, cmap=\"YlGnBu\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Number of predictions')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
