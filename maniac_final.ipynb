{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric as tg\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pathlib import PurePath\n",
    "import os\n",
    "import scipy.optimize\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from xml.dom import minidom\n",
    "\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method to create one hot encoders\n",
    "\n",
    "Input: Array with string\n",
    "'''\n",
    "def one_hot_string(map):\n",
    "    values = np.array(map)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    \n",
    "    return onehot_encoded\n",
    "\n",
    "'''\n",
    "    Get action name from one-hot-encoding\n",
    "'''\n",
    "def get_action_from_encoding(enc):\n",
    "    idx = _actions.index(enc)\n",
    "    return action_map[idx], idx\n",
    "\n",
    "'''\n",
    "    Create a dict with temporal information\n",
    "'''\n",
    "def createTemporalDict(in_dict):\n",
    "    temporal_concat = {}\n",
    "    \n",
    "    for key in in_dict:\n",
    "        temporal_concat[key] = {}\n",
    "        for seq in in_dict[key]:\n",
    "                    temporal_concat[key][seq] = [concatenateTemporal(in_dict[key][seq])]\n",
    "    return temporal_concat\n",
    "\n",
    "'''\n",
    "    See if two nodes match\n",
    "'''\n",
    "def nodesMatch(n1, n_list):\n",
    "    for i, node in enumerate(n_list, start=0):\n",
    "        if node[1] == n1:\n",
    "            return True, i\n",
    "\n",
    "    return False, 0\n",
    "\n",
    "'''\n",
    "    Calculate the temporal edges\n",
    "    # nodes will start at node_index_list.last + 1\n",
    "'''\n",
    "def calculateTemporalEdges(full_gr, nodes, index_list):\n",
    "    temporal_rel = _relations[spatial_map.index(\"temporal\")]\n",
    "    old_nodes = []\n",
    "    node_cnt = index_list[-1]\n",
    "\n",
    "\n",
    "    for index in index_list:\n",
    "        old_nodes.append(full_gr.nodes[index])\n",
    "\n",
    "    for index in index_list:\n",
    "        match, ind = nodesMatch(full_gr.nodes[index], nodes)\n",
    "        if match:\n",
    "            full_gr.add_edge(index, node_cnt, edge_attr=temporal_rel)\n",
    "            node_cnt += 1\n",
    "\n",
    "'''\n",
    "    Function to create the temporal information between graphs.\n",
    "    Input: list of graphs\n",
    "'''\n",
    "def concatenateTemporal(graphs):\n",
    "    graph_nx = nx.DiGraph()\n",
    "    graph_nx.graph[\"features\"] = graphs[0].graph['features']\n",
    "    node_cnt = 0\n",
    "    node_index_list = []\n",
    "\n",
    "    for i, graph in enumerate(graphs, start=0):\n",
    "\n",
    "        if len(node_index_list) > 0:\n",
    "            calculateTemporalEdges(graph_nx, graph.nodes(data=True), node_index_list)\n",
    "\n",
    "        node_index_list = []\n",
    "\n",
    "        for node in graph.nodes(data=True):\n",
    "            graph_nx.add_node(node_cnt, x=node[1]['x'])\n",
    "            node_index_list.append(node_cnt)\n",
    "            node_cnt += 1\n",
    "            \n",
    "        for edge in graph.edges():\n",
    "            graph_nx.add_edge(node_index_list[edge[0]], node_index_list[edge[1]], edge_attr=graph.get_edge_data(edge[0], edge[1])['edge_attr'])\n",
    "\n",
    "    empty_list = []\n",
    "    for node in graph_nx.nodes(data=True):\n",
    "        if node[1] == {}:\n",
    "            empty_list.append(node[0])\n",
    "\n",
    "    for node in empty_list:\n",
    "        graph_nx.remove_node(node)\n",
    "\n",
    "\n",
    "    return graph_nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be hard-coded and in alphabetic order.\n",
    "action_map  = [\"chopping\", \"cutting\", \"hiding\", \"pushing\", \"putontop\", \"stirring\", \"takedown\", \"uncover\"]\n",
    "spatial_map = [\"noconnection\", \"temporal\", \"touching\"]\n",
    "objects     = ['Apple', 'Arm', 'Ball', 'Banana', 'Body', 'Bowl', 'Box', 'Bread', \n",
    "               'Carrot', 'Chopper', 'Cucumber', 'Cup', 'Hand', \n",
    "               'Knife', 'Liquid', 'Pepper', 'Plate', 'Sausage', 'Slice', 'Spoon', 'null']\n",
    "\n",
    "# Creates one hot encodings for actions, relations and objects.\n",
    "_relations = one_hot_string(spatial_map).tolist()\n",
    "_actions = one_hot_string(action_map).tolist()\n",
    "_objects = one_hot_string(objects).tolist()\n",
    "\n",
    "# Folder with MANIAC keyframes\n",
    "_FOLDER = os.getcwd() + \"/maniac/\"\n",
    "\n",
    "# If you have MANIAC data in different folder\n",
    "_MANIAC_DATA_FOLDER = \"/data/tmp/master_thesis/MANIAC/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BOWL:\", _objects[objects.index('Bowl')])\n",
    "print(\"Box:\", _objects[objects.index('Box')])\n",
    "print(\"Hand:\", _objects[objects.index('Hand')])\n",
    "\n",
    "print(\"no connect:\", _relations[spatial_map.index(\"noconnection\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Method to find all xml files.\n",
    "\n",
    "Input: String of folder\n",
    "'''\n",
    "def find_xmls(path=_FOLDER):\n",
    "    all_xmls = []\n",
    "    for filename in Path(path).rglob('*.xml'):\n",
    "        all_xmls.append(filename)\n",
    "    return all_xmls\n",
    "\n",
    "'''\n",
    "Method to split xml into action and s\n",
    "\n",
    "Input: Array with strings of xml \n",
    "'''\n",
    "def parse_xml_info(xml):\n",
    "    if isinstance(xml, Path):\n",
    "        ss = str(PurePath(xml))\n",
    "        if ss[-3:] != 'xml':\n",
    "            raise ValueError(\"Must be XML! recieved {}\".format(ss))\n",
    "        \n",
    "        path_split = xml.parts\n",
    "        split = path_split[-2].split('_')\n",
    "        action = \"\".join(split[:-1]).lower()\n",
    "        seq = split[-1]\n",
    "        \n",
    "        return action, int(seq)\n",
    "    else:\n",
    "        raise ValueError(\"Must be XML! recieved {}\".format(xml))\n",
    "# USAGE\n",
    "#all_xmls = find_xmls()\n",
    "#parse_xml_info(_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import xml.etree.ElementTree as ET\n",
    "from glob import glob\n",
    "\n",
    "'''\n",
    "Boolean flag to skip edge connections.\n",
    "\n",
    "If set to false:\n",
    "    All spatial relations will be used.\n",
    "\n",
    "If set to true:\n",
    "    Will _ONLY_ use the spatial relation 'touching'\n",
    "'''\n",
    "_SKIP_CONNECTIONS = False\n",
    "\n",
    "\n",
    "'''\n",
    "A SEC parser\n",
    "\n",
    "Create networkx graphs from MANIACs GraphML.xml files.\n",
    "\n",
    "'''\n",
    "\n",
    "class SECParser():\n",
    "    \n",
    "    def __init__(self):\n",
    "        try: \n",
    "            import xml.etree.ElementTree as ET\n",
    "        except ImportError:\n",
    "            raise ImportError('We need xml.elementtree.ElementTree!')\n",
    "        \n",
    "        self.graph_dict = {}\n",
    "        self.action_dict = {}\n",
    "        self.actions = {}\n",
    "        \n",
    "    def __call__(self, path=None, action=None):\n",
    "        if path is not None:\n",
    "            self.xml = ET.parse(path)\n",
    "            self.path = path\n",
    "        else:\n",
    "            raise ValueError(\"Must specify path!\")\n",
    "        \n",
    "        # Get all XML with action and sequence\n",
    "        self.action, self.seq = parse_xml_info(self.path)\n",
    "        \n",
    "        # Create the graphs\n",
    "        self.create_graph(self.xml)\n",
    "        \n",
    "        # Returns all keyframes as a list\n",
    "        return self.get_keyframes_as_list()\n",
    "    \n",
    "    '''\n",
    "    \n",
    "        Method to create networkx graph\n",
    "    \n",
    "    '''\n",
    "    def create_graph(self, graph_element):\n",
    "        root = graph_element.getroot()\n",
    "        node_count = 0\n",
    "        nodes_map = {}\n",
    "        keep_graph = True\n",
    "        replace_object_dict = {}\n",
    "        \n",
    "        # Objects in MANIAC GraphML is defined as they appear in the frame.\n",
    "        # This helps to use correct item label for each node. \n",
    "        for root_replace_object in root.iter('ReplaceObject'):\n",
    "            replace_objects = root_replace_object.findall('Object')\n",
    "            \n",
    "            # Creates a dict to store object id that and the new replaced values.\n",
    "            for obj in replace_objects:\n",
    "                replace_object_dict[int(obj.attrib['id'])] = obj.attrib['obj']\n",
    "        \n",
    "        for keyframe in root.iter('KeyFrame'):\n",
    "            # Creates a Directed graph structure\n",
    "            graph = nx.DiGraph()\n",
    "            # Add graph features\n",
    "            graph.graph[\"features\"] = _actions[action_map.index(self.action)]\n",
    "            graph.graph['seq'] = self.seq\n",
    "            \n",
    "            # Gets the action's identifier\n",
    "            action_id = np.argmax(_actions[action_map.index(self.action)])\n",
    "            self.actions[action_id] = action_map.index(self.action)\n",
    "            \n",
    "            # Add all nodes and edges to list.\n",
    "            keyframe_id = keyframe.attrib['ID'] \n",
    "            nodes = keyframe.findall('Node')\n",
    "            edges = keyframe.findall('Edge')\n",
    "            \n",
    "            skip_nodes = []\n",
    "            \n",
    "            for node in nodes:\n",
    "                # This is not used yet, \n",
    "                # but for future development the position of the node may be used.\n",
    "                pos_X = float(node.attrib['pos_X'])\n",
    "                pos_Y = float(node.attrib['pos_Y'])\n",
    "                pos_Z = float(node.attrib['pos_Z'])\n",
    "                n_type = node.attrib['type']\n",
    "                n_id = node.attrib['id']\n",
    "                \n",
    "                # Check if the node should be added to nodes_map and gives the node a new value.\n",
    "                # The value of nodes need to be incremental order such as [0, 1, 2...., n]\n",
    "                if nodes_map.get(n_id) is None:\n",
    "                    if objects.index(replace_object_dict.get(int(n_id))) != objects.index('null'):\n",
    "                        nodes_map[n_id] = node_count\n",
    "                        node_count += 1\n",
    "                    else:\n",
    "                        skip_nodes.append(n_id)\n",
    "                \n",
    "                # Replace the nodes id with correct x feature.\n",
    "                # If acceptable, the node is added to the graph with one hot encoding of the object.\n",
    "                if int(n_id) in replace_object_dict:\n",
    "                    if objects.index(replace_object_dict.get(int(n_id))) != objects.index('null'):\n",
    "                        graph.add_node(nodes_map[n_id], x=_objects[objects.index(replace_object_dict.get(int(n_id)))])\n",
    "                    \n",
    "                else:\n",
    "                    # If object not defined it will be called null,\n",
    "                    # this is very bad with missing features.\n",
    "                    graph.add_node(nodes_map[n_id], x=_objects[objects.index(\"null\")])\n",
    "                    print(\"This is very bad, missing features! Please look at:\")\n",
    "                    print(\"Action:\", self.action, \"seq:\", self.seq, \"keyframe:\", keyframe_id, \"node id:\", n_id)\n",
    "                \n",
    "            # Check if the graph contains and edges. If not, the graph will be removed.\n",
    "            if len(edges) == 0:\n",
    "                print(\"[SECParser] NO edge found. Need at least 1 edge for GraphNet. Added dummy value\")\n",
    "                #graph.add_edge(0,0, features=_relations[spatial_map.index(\"dummy_value\")])\n",
    "                keep_graph = False\n",
    "            \n",
    "            # Adds the edge relationships between nodes.\n",
    "            for edge in edges:\n",
    "                target = edge.attrib['target']\n",
    "                relation = (edge.attrib['relation']).lower()\n",
    "                \n",
    "                # decide if noconneciton should be a edge or not.\n",
    "                if relation == 'noconnection' and _SKIP_CONNECTIONS:\n",
    "                    continue\n",
    "                source = edge.attrib['source']\n",
    "                \n",
    "                # Nodes that shall be removed should not have any edges. This prevents uncessary edges.\n",
    "                if target in skip_nodes:\n",
    "                    continue\n",
    "                if source in skip_nodes:\n",
    "                    continue\n",
    "                \n",
    "                \n",
    "                graph.add_edge(nodes_map[target], nodes_map[source], edge_attr=_relations[spatial_map.index(relation)])\n",
    "            \n",
    "            _check_graph_remapping_nodes = check_graph(graph)\n",
    "            # Check that node mapping is in the right way.\n",
    "            if _check_graph_remapping_nodes:\n",
    "                graph = nx.relabel_nodes(graph, _check_graph_remapping_nodes)\n",
    "            \n",
    "            # Adds the graph into a dict for the action id and corresponding sequence id.\n",
    "            # Example: HIDING_SECs\\Hiding_01\\GraphML.xml\n",
    "            # graph_dict['hiding'][1][...] will have the current graphs.\n",
    "            if self.graph_dict.get(action_id) is None:\n",
    "                if keep_graph:\n",
    "                    self.graph_dict[action_id] = {}\n",
    "                    self.graph_dict[action_id][self.seq] = [graph]\n",
    "                else:\n",
    "                    keep_graph = True\n",
    "            else:\n",
    "                if self.graph_dict[action_id].get(self.seq) is None:\n",
    "                    if keep_graph:\n",
    "                        self.graph_dict[action_id][self.seq] = [graph]\n",
    "                    else:\n",
    "                        keep_graph = True\n",
    "                else:\n",
    "                    if keep_graph:\n",
    "                        self.graph_dict[action_id][self.seq].append(graph)\n",
    "                    else:\n",
    "                        print(\"[SECParser] Did not not add graph to list, due to 1 node. GraphNet requires at least 2 nodes.\")\n",
    "                        keep_graph = True\n",
    "    \n",
    "    def get_action(self, action):\n",
    "        return self.actions[action]\n",
    "                    \n",
    "    def get_keyframes_as_list(self):\n",
    "        return self.graph_dict\n",
    "    \n",
    "    def get_graph_dict(self):\n",
    "        return self.graph_dict\n",
    "\n",
    "\n",
    "def _check_key(node, key):\n",
    "    return node != key\n",
    "\n",
    "'''\n",
    "    Method to check if graph have data features and with creates node id to be in right order.\n",
    "    Usually only called internally from SECParser.\n",
    "'''\n",
    "def check_graph(graph_nx):\n",
    "    map_dict = {}\n",
    "    for node_i, (key, data) in enumerate(graph_nx.nodes(data=True)):\n",
    "        if _check_key(node_i, key) and data['x'] is not None:\n",
    "            map_dict[key] = node_i\n",
    "    \n",
    "    if len(map_dict) > 0:\n",
    "        return map_dict\n",
    "\n",
    "'''\n",
    " Method to create a big list of the action dict.\n",
    " \n",
    " Input: dict with action, seq and graphs.\n",
    "\n",
    "'''\n",
    "def create_big_list(input_dict):\n",
    "    big_list = []\n",
    "    manipulation_actions = list(input_dict.keys())\n",
    "    \n",
    "    for action in sorted(manipulation_actions):\n",
    "        variations_of_manipulation = sorted(input_dict[action].keys())\n",
    "        \n",
    "        for variation in variations_of_manipulation:\n",
    "            num_of_graphs = len(input_dict[action][variation])\n",
    "            \n",
    "            for graph in range(num_of_graphs):\n",
    "                big_list.append(input_dict[action][variation][graph])\n",
    "    \n",
    "    return big_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "'''\n",
    "\n",
    "    Creates MANIAC dataset to work with PyTorch Geometric.\n",
    "\n",
    "'''\n",
    "class MANIAC(Dataset):\n",
    "    def __init__(self, root_dir, window, temporal=False):\n",
    "        self.window = window\n",
    "        self.root_dir = root_dir\n",
    "        self.all_xmls = find_xmls(self.root_dir)\n",
    "        self.sp = SECParser()\n",
    "        self.temporal = temporal\n",
    "        \n",
    "        for xml in self.all_xmls:\n",
    "            self.dict_with_graphs = self.sp(xml)\n",
    "        \n",
    "        self.samples = create_big_list(self.dict_with_graphs)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples) - self.window\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.window > 0:\n",
    "            \n",
    "            x = self.samples[idx:idx+self.window]\n",
    "        \n",
    "            current_action = self.samples[idx].graph['features']\n",
    "            step_back = 0\n",
    "\n",
    "            for i in range(self.window):\n",
    "                if self.samples[idx+i].graph['features'] != current_action:\n",
    "                    step_back += 1\n",
    "\n",
    "            if step_back > 0:\n",
    "                x = self.samples[idx-step_back:idx+self.window-step_back]\n",
    "            else:\n",
    "                x = self.samples[idx:idx+self.window]\n",
    "        else:\n",
    "            x = self.samples[idx]\n",
    "            \n",
    "        if self.temporal:\n",
    "            return concatenateTemporal(x)\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    This is used to create new datasets.\n",
    "    \n",
    "    Example:\n",
    "    train_set = MANIAC( \"FOLDER_TO_MANIAC_GRAPHML\", window, temporal)\n",
    "    \n",
    "    if window = 0, 1 graph will be made.\n",
    "    if window > 0, x number of graphs will be created together\n",
    "    \n",
    "    temporal = False, will not add temporal information between nodes\n",
    "    if tempral = True, will add temporal information between nodes\n",
    "\n",
    "'''\n",
    "_SAVE_RAW_DATA = False\n",
    "_CREATE_DATASET = False\n",
    "\n",
    "_TIME_WINDOW = 4\n",
    "_TEMPORAL = True\n",
    "\n",
    "if _CREATE_DATASET:\n",
    "    train_set = MANIAC(_MANIAC_DATA_FOLDER + \"training/\", _TIME_WINDOW, _TEMPORAL)\n",
    "    val_set = MANIAC(_MANIAC_DATA_FOLDER + \"validation/\", _TIME_WINDOW, _TEMPORAL)\n",
    "    test_set = MANIAC(_MANIAC_DATA_FOLDER + \"testing/\", _TIME_WINDOW, _TEMPORAL)\n",
    "\n",
    "\n",
    "# USED TO SAVE RAW TRAINING DATA\n",
    "if _SAVE_RAW_DATA:\n",
    "    with open(os.path.join(_FOLDER + \"raw/training_\" + str(_TIME_WINDOW) + \"w.pt\"), 'wb') as f:\n",
    "                torch.save(train_set, f)\n",
    "\n",
    "    with open(os.path.join(_FOLDER + \"raw/validation_\" + str(_TIME_WINDOW) + \"w.pt\"), 'wb') as df:\n",
    "                torch.save(val_set, df)\n",
    "\n",
    "    with open(os.path.join(_FOLDER + \"raw/test_\" + str(_TIME_WINDOW) + \"w.pt\"), 'wb') as df:\n",
    "                torch.save(test_set, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_tar)\n",
    "\n",
    "'''\n",
    "\n",
    "    Creates MANIAC dataset to work with PyTorch Geometric.\n",
    "    \n",
    "    Read more about it at\n",
    "    https://pytorch-geometric.readthedocs.io/en/latest/notes/create_dataset.html#creating-in-memory-datasets\n",
    "\n",
    "'''\n",
    "class ManiacDS(InMemoryDataset):\n",
    "    def __init__(self,\n",
    "                root,\n",
    "                dset=\"train\",\n",
    "                transform=None):\n",
    "        super(ManiacDS, self).__init__(root, transform)\n",
    "        \n",
    "        if dset == \"train\":\n",
    "            path = self.processed_paths[0]\n",
    "        elif dset == \"valid\":\n",
    "            path = self.processed_paths[1]\n",
    "        else:\n",
    "            path = self.processed_paths[2]\n",
    "\n",
    "        self.data, self.slices = torch.load(path)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['training_' + str(_TIME_WINDOW) + 'w.pt', 'validation_' + str(_TIME_WINDOW) + 'w.pt', 'test_' + str(_TIME_WINDOW) + 'w.pt']\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['training_' + str(_TIME_WINDOW) + 'w.pt', 'validation_' + str(_TIME_WINDOW) + 'w.pt', 'test_' + str(_TIME_WINDOW) + 'w.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        return\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)\n",
    "    \n",
    "    def process(self):\n",
    "        big_slices = []\n",
    "        for raw_path, path in zip(self.raw_paths, self.processed_paths):\n",
    "            big_data = []\n",
    "            graphs = torch.load(raw_path)\n",
    "            \n",
    "            # Creates torch_geometric data from networkx graphs\n",
    "            # https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs\n",
    "            for graph in graphs:\n",
    "                G = nx.convert_node_labels_to_integers(graph)\n",
    "                G = G.to_directed() if not nx.is_directed(G) else G\n",
    "                edge_index = torch.tensor(list(G.edges)).t().contiguous()\n",
    "\n",
    "                data = {}\n",
    "\n",
    "                for i, (_, feat_dict) in enumerate(G.nodes(data=True)):\n",
    "                    for key, value in feat_dict.items():\n",
    "                        data[key] = [value] if i == 0 else data[key] + [value]\n",
    "\n",
    "                for i, (_, _, feat_dict) in enumerate(G.edges(data=True)):\n",
    "                    for key, value in feat_dict.items():\n",
    "                        data[key] = [value] if i == 0 else data[key] + [value]\n",
    "\n",
    "                for key, item in data.items():\n",
    "                    try:\n",
    "                        data[key] = torch.tensor(item)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "                \n",
    "                # Creates the tg data\n",
    "                data['edge_index'] = edge_index.view(2, -1)\n",
    "                data = tg.data.Data.from_dict(data)\n",
    "                data.y = torch.tensor(graph.graph['features'])\n",
    "                \n",
    "                # This is not used, can be useful in future development if the sequence id is needed.\n",
    "                #data.seq = torch.tensor([graph.graph['seq']])\n",
    "                \n",
    "                if _SKIP_CONNECTIONS:\n",
    "                    if data.edge_attr is not None:\n",
    "                        big_data.append(data)\n",
    "                else:\n",
    "                    big_data.append(data)\n",
    "            \n",
    "            for graph in big_data:\n",
    "                if graph.edge_attr is None:\n",
    "                    print(graph)\n",
    "                    print(graph.edge_attr)\n",
    "                    print(action_map[graph.y.argmax().item()])\n",
    "                    break\n",
    "            \n",
    "            torch.save(self.collate(big_data), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ManiacDS(_FOLDER, \"train\")\n",
    "test_ds = ManiacDS(_FOLDER, \"test\")\n",
    "valid_ds = ManiacDS(_FOLDER, \"valid\")\n",
    "\n",
    "print(len(train_dataset)+len(test_ds)+len(valid_ds))\n",
    "print(len(test_ds))\n",
    "print(len(valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "max_count = 1\n",
    "_bs = 1\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=_bs, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=_bs, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=_bs, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_batch, to_dense_adj, to_scipy_sparse_matrix\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "'''\n",
    "    Creates a dense adjacency matrix from pg data.\n",
    "    With normalization\n",
    "'''\n",
    "def to_dense_adj_max_node(edge_index, x, edge_attr, batch=None, max_node=None):\n",
    "    if batch is None:\n",
    "        batch = edge_index.new_zeros(edge_index.max().item() + 1)\n",
    "    \n",
    "    batch_size = batch[-1].item() + 1\n",
    "    \n",
    "    if max_node is None:\n",
    "        max_num_nodes = num_nodes.max().item()\n",
    "    else:\n",
    "        max_num_nodes = max_node\n",
    "    \n",
    "    one = batch.new_ones(batch.size(0))\n",
    "    num_nodes = scatter_add(one, batch, dim=0, dim_size=batch_size)\n",
    "    cum_nodes = torch.cat([batch.new_zeros(1), num_nodes.cumsum(dim=0)])\n",
    "    \n",
    "    size = [batch_size, max_num_nodes, max_num_nodes]\n",
    "    \n",
    "    size = size\n",
    "    dtype = torch.float\n",
    "    \n",
    "    adj = torch.zeros(size, dtype=dtype, device=edge_index.device)\n",
    "\n",
    "    edge_index_0 = batch[edge_index[0]].view(1, -1)\n",
    "    edge_index_1 = edge_index[0] - cum_nodes[batch][edge_index[0]]\n",
    "    edge_index_2 = edge_index[1] - cum_nodes[batch][edge_index[1]]\n",
    "    \n",
    "    # Normalize the edges on the length of pre-defined spatial objects.\n",
    "    _ea = []\n",
    "    for ea in edge_attr:\n",
    "        _ea.append((ea[0].item()+1)/len(spatial_map))\n",
    "\n",
    "    adj[edge_index_0, edge_index_1, edge_index_2] = torch.FloatTensor(_ea).cuda()\n",
    "\n",
    "    # Normalize objects in the diagonal\n",
    "    objects_sum = x.argmax(dim=1).type(dtype)\n",
    "    objects_sum = objects_sum/len(_objects)\n",
    "\n",
    "    object_size = [batch_size, num_nodes.max().item()]\n",
    "    object_mat = torch.zeros(object_size, dtype=dtype, device=edge_index.device)\n",
    "    \n",
    "    obj_offset = 0\n",
    "    \n",
    "    # Creates the adjacency matrix of size [max_node*max_node].\n",
    "    for b in range(batch_size):\n",
    "        temp = torch.zeros(num_nodes.max().item(), dtype=dtype, device=edge_index.device)\n",
    "        _obj = objects_sum[obj_offset:(obj_offset+num_nodes[b])].type(dtype)\n",
    "        obj_offset += num_nodes[b]\n",
    "        dd = torch.cat((_obj, temp), dim=0)\n",
    "        dd = dd[:num_nodes.max().item()]\n",
    "        object_mat[b] = dd\n",
    "            \n",
    "    adj.as_strided(object_mat.size(), [adj.stride(0), adj.size(2) + 1]).copy_(object_mat)\n",
    "    \n",
    "    # Error check to see that the diagonal is not zero.\n",
    "    for i in range(len(adj)):\n",
    "        if torch.diag(adj[i]).sum().item() == 0:\n",
    "            print(\"ERROR! ZERO DIAGONAL!\", i)\n",
    "\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_batch, to_dense_adj, to_scipy_sparse_matrix\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "'''\n",
    "    Creates a dense adjacency matrix from pg data.\n",
    "    Without normalization\n",
    "'''\n",
    "def to_dense_adj_max_node(edge_index, x, edge_attr, batch=None, max_node=None):\n",
    "    if batch is None:\n",
    "        batch = edge_index.new_zeros(edge_index.max().item() + 1)\n",
    "    \n",
    "    batch_size = batch[-1].item() + 1\n",
    "    \n",
    "    if max_node is None:\n",
    "        max_num_nodes = num_nodes.max().item()\n",
    "    else:\n",
    "        max_num_nodes = max_node\n",
    "    \n",
    "    one = batch.new_ones(batch.size(0))\n",
    "    num_nodes = scatter_add(one, batch, dim=0, dim_size=batch_size)\n",
    "    cum_nodes = torch.cat([batch.new_zeros(1), num_nodes.cumsum(dim=0)])\n",
    "    \n",
    "    size = [batch_size, max_num_nodes, max_num_nodes]\n",
    "    \n",
    "    size = size\n",
    "    dtype = torch.float\n",
    "    \n",
    "    adj = torch.zeros(size, dtype=dtype, device=edge_index.device)\n",
    "\n",
    "    edge_index_0 = batch[edge_index[0]].view(1, -1)\n",
    "    edge_index_1 = edge_index[0] - cum_nodes[batch][edge_index[0]]\n",
    "    edge_index_2 = edge_index[1] - cum_nodes[batch][edge_index[1]]\n",
    "    \n",
    "    # Normalize the edges on the length of pre-defined spatial objects.\n",
    "    _ea = []\n",
    "    for ea in edge_attr:\n",
    "        _ea.append(1)\n",
    "\n",
    "    adj[edge_index_0, edge_index_1, edge_index_2] = torch.FloatTensor(_ea).cuda()\n",
    "\n",
    "    # Normalize objects in the diagonal\n",
    "    objects_sum = x.argmax(dim=1).type(dtype)\n",
    "    objects_sum[objects_sum > 0] = 1\n",
    "\n",
    "    object_size = [batch_size, num_nodes.max().item()]\n",
    "    object_mat = torch.zeros(object_size, dtype=dtype, device=edge_index.device)\n",
    "    \n",
    "    obj_offset = 0\n",
    "    \n",
    "    # Creates the adjacency matrix of size [max_node*max_node].\n",
    "    for b in range(batch_size):\n",
    "        temp = torch.zeros(num_nodes.max().item(), dtype=dtype, device=edge_index.device)\n",
    "        _obj = objects_sum[obj_offset:(obj_offset+num_nodes[b])].type(dtype)\n",
    "        obj_offset += num_nodes[b]\n",
    "        dd = torch.cat((_obj, temp), dim=0)\n",
    "        dd = dd[:num_nodes.max().item()]\n",
    "        object_mat[b] = dd\n",
    "            \n",
    "    adj.as_strided(object_mat.size(), [adj.stride(0), adj.size(2) + 1]).copy_(object_mat)\n",
    "    \n",
    "    # Error check to see that the diagonal is not zero.\n",
    "    for i in range(len(adj)):\n",
    "        if torch.diag(adj[i]).sum().item() == 0:\n",
    "            print(\"ERROR! ZERO DIAGONAL!\", i)\n",
    "\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_nodes_train = max([len(i.x) for i in train_dataset])\n",
    "print(\"max in train:\", max_num_nodes_train)\n",
    "\n",
    "max_num_nodes_valid = max([len(i.x) for i in valid_ds])\n",
    "print(\"max in train:\", max_num_nodes_valid)\n",
    "\n",
    "max_num_nodes_test = max([len(i.x) for i in test_ds])\n",
    "print(\"max in train:\", max_num_nodes_test)\n",
    "\n",
    "max_num_nodes = max(max_num_nodes_test, max_num_nodes_train, max_num_nodes_valid)\n",
    "print(\"MAX:\", max_num_nodes)\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, ReLU, ELU\n",
    "from torch_geometric.nn import NNConv, radius_graph, fps, global_mean_pool\n",
    "from torch_scatter import scatter_mean\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "input_size=len(action_map) # static value\n",
    "output_size=len(action_map) # static value\n",
    "channels = 64\n",
    "\n",
    "_decoder_in = 32\n",
    "\n",
    "_PRINT = False # Used for debugging\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lin = torch.nn.Linear(len(objects), channels)\n",
    "\n",
    "        nn = Sequential(Linear(len(spatial_map), 64), ReLU(), Linear(64, channels * channels*2 ))\n",
    "\n",
    "        self.conv1 = NNConv(channels, channels*2, nn, aggr='mean') \n",
    "        self.bn1 = BatchNorm(channels*2)\n",
    "        self.conv2 = NNConv(channels*2, channels, nn, aggr='mean')\n",
    "        \n",
    "        nn2 = Sequential(Linear(len(spatial_map), 64), ReLU(), Linear(64, _decoder_in * channels*2 ))\n",
    "        self.mu = NNConv(channels*2, _decoder_in, nn2, aggr='max')\n",
    "        self.logvar = NNConv(channels*2, _decoder_in, nn2, aggr='max')\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        out = F.relu(self.lin(data.x)) # Fully connected\n",
    "        \n",
    "        # Action prediction\n",
    "        hidden = F.relu(self.conv1(out, data.edge_index, data.edge_attr)) # conv1\n",
    "        hidden = self.bn1(hidden)\n",
    "        conv2_out = F.relu(self.conv2(hidden, data.edge_index, data.edge_attr)) # conv2\n",
    "        \n",
    "        # Reconstruction\n",
    "        mu = self.mu(hidden, data.edge_index, data.edge_attr)\n",
    "        logvar = self.logvar(hidden, data.edge_index, data.edge_attr)\n",
    "        \n",
    "        mu = scatter_mean(mu, batch, dim=0)\n",
    "        logvar = scatter_mean(logvar, batch, dim=0)\n",
    "        \n",
    "        p_x = scatter_mean(conv2_out, batch, dim=0)\n",
    "        \n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        if self.training:\n",
    "            return std * eps + mu, logvar, mu, p_x\n",
    "        else:\n",
    "            return mu, logvar, mu, p_x\n",
    "\n",
    "class Predictor(torch.nn.Module):\n",
    "    def __init__(self, input_size, seq_len, hidden_size, n_layers):\n",
    "        super(Predictor, self).__init__()\n",
    "        \n",
    "        self.prev_hidden = None\n",
    "        self.bs = _bs\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(self.input_size, self.hidden_size, self.n_layers, dropout=0.1, batch_first=True)\n",
    "        self.lin1 = torch.nn.Linear(self.hidden_size, len(action_map))\n",
    "    \n",
    "    def forward(self, p_x):\n",
    "        \n",
    "        if self.prev_hidden is None:\n",
    "            self.prev_hidden = (torch.zeros(self.n_layers, self.bs, self.hidden_size).cuda(),\n",
    "                                torch.zeros(self.n_layers, self.bs, self.hidden_size).cuda())\n",
    "\n",
    "\n",
    "        input_reshape = p_x.reshape( self.bs, self.seq_len, -1 ).to(device)\n",
    "\n",
    "        q, h = self.lstm( input_reshape , self.prev_hidden )\n",
    "        \n",
    "        self.prev_hidden = repackage_hidden(h)\n",
    "        \n",
    "        out = self.lin1(q[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(_decoder_in, 64)\n",
    "        self.fc2 = nn.Linear(64, max_num_nodes*max_num_nodes)\n",
    "    \n",
    "    def forward(self, z_x):\n",
    "\n",
    "        out = F.relu(self.fc1(z_x))\n",
    "        out = self.fc2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class djNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(djNet, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        self.predictor = Predictor(8, 8, 8, 4)\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z, logvar, mu, p_x = self.encoder(x)\n",
    "        p_z = self.predictor(p_x)\n",
    "        q_z = self.decoder(z)\n",
    "        \n",
    "        return q_z, logvar, mu, z, p_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = djNet().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_criterion(inputs, targets, logvar, mu, ap_inputs, ap_targets):\n",
    "    # Reconstruction loss\n",
    "    bce_loss = F.binary_cross_entropy(inputs, targets, reduction=\"sum\")\n",
    "    \n",
    "    # Action prediction loss\n",
    "    ap_loss = ap_criterion(ap_inputs, ap_targets)\n",
    "\n",
    "    # Regularization term\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())    \n",
    "\n",
    "    return bce_loss + kl_loss, ap_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#writer = SummaryWriter(comment=\"MANIAC_4w_dropout02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(loader, model):\n",
    "    model.train()\n",
    "    \n",
    "    recon_loss_all = 0\n",
    "    ap_loss_all = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "\n",
    "        y_hat, logvar, mu, _, y_ap = model(data)\n",
    "        prediction = y_hat.view(_bs, -1, max_num_nodes)\n",
    "\n",
    "        # Creating targets\n",
    "        target_adj = to_dense_adj_max_node(data.edge_index, data.x, data.edge_attr, data.batch, max_num_nodes).cuda()\n",
    "        target = data.y.view(_bs, -1)\n",
    "        y_ap_true = target.argmax(axis=1)\n",
    "\n",
    "        # Compute loss\n",
    "        recon_loss, ap_loss = loss_criterion(prediction, target_adj, logvar, mu, y_ap, y_ap_true)\n",
    "        net_loss = recon_loss * 0.7 + ap_loss\n",
    "\n",
    "        # Compute gradients and updates weights.\n",
    "        net_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        recon_loss_all += recon_loss.item()\n",
    "        ap_loss_all += ap_loss.item()\n",
    "    \n",
    "    return recon_loss_all/(len(loader)*_bs), ap_loss_all/(len(loader)*_bs)\n",
    "\n",
    "def test(loader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    recon_loss_all = 0\n",
    "    ap_loss_all = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "\n",
    "        y_hat, logvar, mu, _, y_ap = model(data)\n",
    "        prediction = y_hat.view(_bs, -1, max_num_nodes)\n",
    "\n",
    "        # Creating targets\n",
    "        target_adj = to_dense_adj_max_node(data.edge_index, data.x, data.edge_attr, data.batch, max_num_nodes).cuda()\n",
    "        target = data.y.view(_bs, -1)\n",
    "        y_ap_true = target.argmax(axis=1)\n",
    "        \n",
    "        pred = y_ap.max(1)[1]\n",
    "\n",
    "        # Compute loss\n",
    "        recon_loss, ap_loss = loss_criterion(prediction, target_adj, logvar, mu, y_ap, y_ap_true)\n",
    "\n",
    "        recon_loss_all += recon_loss.item()\n",
    "        ap_loss_all += ap_loss.item()\n",
    "        correct += pred.eq(y_ap_true).sum().item()\n",
    "    \n",
    "    return recon_loss_all/(len(loader)*_bs), ap_loss_all/(len(loader)*_bs), correct/(len(loader)*_bs)\n",
    "\n",
    "        \n",
    "def super_test(loader, model):\n",
    "    model.eval()\n",
    "    ap_predict_list = np.array([])\n",
    "    ap_gt_list = np.array([])\n",
    "    \n",
    "    reconstruct_predict_list = []\n",
    "    reconstruct_gt_list = []\n",
    "    num_nodes_list = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        batch_size = data.batch[-1].item() + 1\n",
    "\n",
    "        y_hat, logvar, mu, _, y_ap = model(data)\n",
    "        pred = y_ap.max(1)[1]\n",
    "        \n",
    "        batch_size = data.batch[-1].item() + 1\n",
    "\n",
    "        one = data.batch.new_ones(data.batch.size(0))\n",
    "        num_nodes = scatter_add(one, data.batch, dim=0, dim_size=batch_size)\n",
    "        num_nodes_list.append(num_nodes.cpu().detach().numpy())\n",
    "        \n",
    "        # Creating targets\n",
    "        target_adj = to_dense_adj_max_node(data.edge_index, data.x, data.edge_attr, data.batch, max_num_nodes).cuda()\n",
    "        target = data.y.view(_bs, -1)\n",
    "        y_ap_true = target.argmax(axis=1)\n",
    "        \n",
    "        prediction = y_hat.view(_bs, -1, max_num_nodes)\n",
    "        ap_predict_list = np.append(ap_predict_list, pred.cpu().detach().numpy())\n",
    "        ap_gt_list = np.append(ap_gt_list, y_ap_true.cpu().detach().numpy())\n",
    "\n",
    "        gr_pred = prediction.cpu().detach().numpy()\n",
    "        gr_gt = target_adj.cpu().detach().numpy()\n",
    "        \n",
    "        reconstruct_predict_list.append(gr_pred)\n",
    "        reconstruct_gt_list.append(gr_gt)                \n",
    "        \n",
    "    return reconstruct_predict_list, reconstruct_gt_list, ap_predict_list, ap_gt_list, num_nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_counter = 0\n",
    "for epoch in range(1, 5001):\n",
    "    \n",
    "    train_recon_loss, train_ap_loss = train(train_loader, model)\n",
    "    _, _, train_ap_acc = test(train_loader, model)\n",
    "    validation_recon_loss, validation_ap_loss, validation_ap_acc = test(valid_loader, model)    \n",
    "\n",
    "    \n",
    "    if False:\n",
    "        writer.add_scalar('AP_Acc/train', train_ap_acc, epoch)\n",
    "        writer.add_scalar('AP_Acc/validation', validation_ap_acc, epoch)\n",
    "\n",
    "        writer.add_scalar('Recon_Loss/train', train_recon_loss, epoch)\n",
    "        writer.add_scalar('Recon_Loss/validation', validation_recon_loss, epoch)\n",
    "\n",
    "        writer.add_scalar('AP_Loss/train', train_ap_loss, epoch)\n",
    "        writer.add_scalar('AP_Loss/validation', validation_ap_loss, epoch)\n",
    "\n",
    "    \n",
    "    print(\"Epoch {:02d}, [T] RLoss: {:.2f}, APLoss: {:.4f}, Acc: {:.2f}% [V] RLoss: {:.2f}, APLoss: {:.4f}, Acc: {:.2f}%\".format( epoch, \n",
    "                                                                           train_recon_loss,\n",
    "                                                                           train_ap_loss,\n",
    "                                                                           train_ap_acc*100,\n",
    "                                                                           validation_recon_loss,\n",
    "                                                                           validation_ap_loss,\n",
    "                                                                           validation_ap_acc*100,\n",
    "                                                                            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SAVE = False\n",
    "if _SAVE:\n",
    "    torch.save({\n",
    "                'epoch': 99,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': 4.110431,\n",
    "                }, \"./MANIAC_final_models/MANIAC_final_4w_dim_64_increase_mu_64.pt\")\n",
    "    print(\"SAVED!\")\n",
    "else:\n",
    "    checkpoint = torch.load(\"./FINAL_RESULTS/2w/maniac_416.pt\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(\"LOADED MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_CURRENT_LOADER = test_loader\n",
    "test_recon_loss, test_ap_loss, test_ap_acc = test(_CURRENT_LOADER, model)\n",
    "print(\"test recon loss:\", test_recon_loss)\n",
    "print(\"test ap loss:\", test_ap_loss)\n",
    "print(\"test ap acc:\", test_ap_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_pred, cr_gt, ap_pred, ap_target, node_list = super_test(_CURRENT_LOADER, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_pred, cr_gt, ap_pred, ap_target, node_list = super_test(_CURRENT_LOADER, model)\n",
    "\n",
    "cm = confusion_matrix(ap_target, ap_pred)\n",
    "print(cm)\n",
    "\n",
    "print(classification_report(ap_target, ap_pred, target_names=action_map, labels=[0,1,2,3,4,5,6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "_PRED_TRESHOLD = 0.3\n",
    "\n",
    "def calc_auc_roc(gt, pred, node_list):\n",
    "\n",
    "    if len(gt) != len(pred):\n",
    "        raise Exception(\"Invalid length of ground truth and prediction! GT {:d} and pred {:d}\".format(len(gt), len(pred))) \n",
    "    \n",
    "    num_matrix = len(gt)\n",
    "    \n",
    "    _correct_node_length = 0\n",
    "    _correct_objects_length = 0\n",
    "    _correct_objects = 0\n",
    "    _total_objects = 0\n",
    "    _roc_auc_score = 0\n",
    "    _max_nodes_in_graph = 0\n",
    "    _average_precision_score = 0\n",
    "    graph_count = 0\n",
    "    \n",
    "    _node_diff_dict = {0: 0}\n",
    "    \n",
    "    for idx in range(num_matrix):\n",
    "        for i in range(len(gt[idx])):\n",
    "            gt_diag = np.round(np.diag(gt[idx][i]))\n",
    "            cr_diag = np.round(np.diag(pred[idx][i]))\n",
    "            cr_nodes = np.count_nonzero(cr_diag)\n",
    "            graph_count += 1\n",
    "        \n",
    "            if node_list[idx][i] == cr_nodes:\n",
    "                _max_nodes_in_graph = node_list[idx][i]\n",
    "                _correct_objects_length += 1\n",
    "                _node_diff_dict[0] += 1\n",
    "            else:\n",
    "                diff = cr_nodes - node_list[idx][i]\n",
    "                if _node_diff_dict.get(diff) is None:\n",
    "                    _node_diff_dict[diff] = 1\n",
    "                else:\n",
    "                    _node_diff_dict[diff] += 1\n",
    "       \n",
    "            gt_flatten = np.ceil(gt[idx][i].flatten())\n",
    "\n",
    "            pred[idx][pred[idx] <= _PRED_TRESHOLD] = 0\n",
    "            pred[idx][pred[idx] > _PRED_TRESHOLD] = 1\n",
    "\n",
    "            cr_flatten = np.ceil(pred[idx][i].flatten())\n",
    "            _roc_auc_score += roc_auc_score(gt_flatten, cr_flatten)\n",
    "            _average_precision_score += average_precision_score(gt_flatten, cr_flatten)\n",
    "    \n",
    "    print(_node_diff_dict)\n",
    "    print(\"Correct node length:\", _correct_objects_length, \"out of\", graph_count, \"graphs.\", _correct_objects_length/num_matrix)\n",
    "    print(\"Correct objects in place:\", _correct_objects, \"out of\", _total_objects, \"objects\")\n",
    "    print(\"Average ROC AUC SCORE:\", _roc_auc_score/graph_count)\n",
    "    print(\"Average precision score:\", _average_precision_score/graph_count)\n",
    "\n",
    "calc_auc_roc(cr_gt, cr_pred, node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=action_map, yticklabels=action_map, cmap=\"YlGnBu\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Normalized')\n",
    "plt.show(block=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=action_map, yticklabels=action_map, cmap=\"YlGnBu\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Number of predictions')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
